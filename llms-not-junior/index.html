<!DOCTYPE html>
<html><head><!-- META --><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><title>LLMs are not junior programmers</title><meta name="description" content="Sometimes better, sometimes worse, always different"><meta name="author" content="Devon Burriss"><link rel="canonical" href="https://devonburriss.me/llms-not-junior/"><meta itemprop="datePublished" content="2025-12-22" id="date"><meta itemprop="dateModified" content="2025-12-22" id="mdate"><meta itemprop="headline" content="LLMs are not junior programmers - Sometimes better, sometimes worse, always different"><meta itemprop="mainEntityOfPage" content="https://devonburriss.me/llms-not-junior/"><meta name="headline" content="LLMs are not junior programmers - Sometimes better, sometimes worse, always different"><link rel="icon" type="image/png" href="/img/favicon16.png" sizes="16x16"><link rel="icon" type="image/png" href="/img/favicon32.png" sizes="32x32"><meta itemprop="name" content="LLMs are not junior programmers"><meta itemprop="description" content="Sometimes better, sometimes worse, always different"><meta itemprop="image" content="https://devonburriss.me/img/posts/2018/team-500.jpg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@DevonBurriss"><meta name="twitter:title" content="LLMs are not junior programmers"><meta name="twitter:description" content="Sometimes better, sometimes worse, always different"><meta name="twitter:creator" content="@DevonBurriss"><meta name="twitter:image" content="https://devonburriss.me/img/posts/2018/team-500.jpg"><meta property="og:title" content="LLMs are not junior programmers"><meta property="og:type" content="article"><meta property="og:url" content="https://devonburriss.me/llms-not-junior/"><meta property="og:image" content="https://devonburriss.me/img/posts/2018/team-500.jpg"><meta property="og:description" content="Sometimes better, sometimes worse, always different"><meta property="og:site_name" content="Devon Burriss&#39; Blog"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/clean-blog.css"><link rel="stylesheet" charset="UTF-8" href="/css/highlight/atom-one-light.css"><link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css"><!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]--></head><body><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class="container-fluid"><div class="navbar-header page-scroll"><button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a class="navbar-brand" href="/">Devon Burriss&#39; Blog</a></div><div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1"><ul class="nav navbar-nav navbar-right"><li><a href="/">Home</a></li><li><a href="/recommended-reading.html">Recommended Reading</a></li><li><a href="/rss.xml"><span class="fa-stack fa-lg"><i class="fa fa-rss fa-stack-1x"></i></span></a></li></ul></div></div></nav><header class="intro-header" style="background-image: url(&#39;/img/backgrounds/bulb-bg.jpg&#39;)"><div class="container-fluid"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="post-heading"><div class="frame"><h1>LLMs are not junior programmers</h1><h2 class="subheading">Sometimes better, sometimes worse, always different</h2><span class="meta" itemprop="author" itemscope="" itemtype="https://schema.org/Person">Posted by <span itemprop="name">Devon Burriss</span> on December 22, 2025</span><span style="display:contents"><hr><a href="/topics/ai-agentic-systems/" title="AI, LLMs, and agentic workflows."><span class="label label-default">AI &amp; Agentic Systems</span></a></span><div></div></div></div></div></div></div></header><article><div class="container-fluid"><div class="row"><div class="col-lg-8"><p>I often hear people compare LLM tools to junior developers. This comparison is not only incorrect, it is holding you back. If you have an incorrect mental model of the tool, you will constantly be surprised by the results. In this post I will explain how viewing the LLM as a junior is holding you back from better outcomes.</p>
<!--more-->
<p>It should be no surprise that a large language model (LLM) is not like a human. The marketing hype has been pushing the Artificial Intelligence narrative for years now though. As social primates, language is integral for how we communicate with other humans, so it is only natural that we anthropomorphise these machines that are so adept at language.</p>
<p>It is important to know what you are dealing with. I summarise it as:</p>
<blockquote>
<p>The LLM is a stateless, stochastic function: <code>(parameters, prompt, runtime config) â†’ output</code></p>
</blockquote>
<p>So what does this mean?</p>
<ul>
<li>Stateless: It does not remember. The output is based on the input.</li>
<li>Stochastic: The next generated token is based on a probability distribution of what has come before in the text. Effectively, it is non-deterministic.<a id="fnref:1" href="#fn:1" class="footnote-ref"><sup>1</sup></a></li>
<li>Function: It generates the next token based on what has come before. The output is the result of a sequence of next most likely tokens.</li>
</ul>
<p>Hopefully, this is a useful grounding as we go through the precise ways that a coding assistant is not like a junior programmer.</p>
<h2 id="a-junior-learns">1. A junior learns</h2>
<p>A junior is responsible for learning from their experience. As they work and are mentored, they gain knowledge and skills that they bring into their next task. They improve.</p>
<p>The agentic tools like Claude, OpenCode, or Copilot do not learn. They are stateless. All context that will determine a high or low quality output needs to be supplied by you or your tooling.</p>
<p>Knowing this as the operator of the agentic coding tool, it is your responsibility to &quot;teach&quot; the agent as you go. The trick is that you need to teach it with every input. I have heard this phrased as &quot;A highly skilled programmer with amnesia&quot;.</p>
<p>There are many techniques for giving these agents memory but the two easiest and most commonly used are:</p>
<ul>
<li><a href="https://agents.md/">AGENTS.md</a> - read by most agentic tools by default</li>
<li><a href="https://lexler.github.io/augmented-coding-patterns/patterns/extract-knowledge/">Extract Knowledge</a> - as you converse with the agent you extract correct knowledge into documents on specific topics for later use</li>
</ul>
<p>The important meta technique to takeaway here is that these are continuous exercises that you are doing. If you only correct the agent in your current session, the learning will be lost. You need to capture the learning somewhere if you want your agent to improve like a junior would.</p>
<h2 id="depth-of-knowledge">2. Depth of knowledge</h2>
<p>The next way that these models diverge from our typical junior programmer is in their depth of &quot;knowledge&quot;. The <code>parameters</code> part of our stateless function can be thought of as a compression of all of the model's training data. These parameters are arrays of numbers that encode the syntax, semantics, knowledge, and biases of the training data and fine-tuning that went into the model's creation.</p>
<p>It is important to know that the knowledge is not stored &quot;as-is&quot; for recall. It is encoded in a &quot;lossy&quot; way in these parameters. These are used to generate responses based on that knowledge that was in the training data.</p>
<p>Functionally, the model has access to more knowledge than any human would be able to consume in a lifetime. This is very different from our junior fresh out of university, college, or a coding bootcamp.</p>
<p>This means we can bounce architecture ideas off our agent and then swap over to asking for tips on UX, then testing, then performance optimisations. When giving it tasks, it will do most far better than a junior would, given the correct guidance.</p>
<p>Remember though, that the &quot;knowledge&quot; captured in the parameters for a model is based on its training data. So if your task requires specialised knowledge, you are going to have to feed that knowledge to the model EVERY SINGLE TIME it is needed (see point 1).</p>
<h2 id="speed-of-execution">3. Speed of execution</h2>
<p>I am not going to spend much time on this. If you have used these tools, you know that they can complete a task faster (and usually cheaper unless something goes wrong) than any human can.</p>
<p>This has an important implication. If you are not learning how these tools work, and when they work well, you will be outperformed by those that do. In the future it will be expected that certain classes of tasks are not done by hand. Conversely, given sufficient proficiency, you should probably not give certain tasks to a coding agent. Learning which is the newest in a long line of things developers are expected to know.</p>
<h2 id="world-model">4. World model</h2>
<p>Returning to output generation. We already covered that the &quot;knowledge&quot; is encoded in a &quot;lossy&quot; way using the arrays of numbers in the parameters. These weighting numbers combined with the runtime configuration of things like <em>temperature</em> determine the next token generated until the full output is returned.</p>
<p>It is important to notice that this stochastic model contains nothing that represents a model of the real world, other than that the training data was created in the real world. The LLM has no way of testing its output with reality, because it <em>understands neither its output nor the real world</em>.</p>
<p>When there is a mismatch, this is referred to as hallucinating. <em>Hallucination is perception in the absence of stimulus</em>. These models have no stimulus. They have no model of the real world to test their output on. For example, it does not know that <code>if</code> is followed by a condition; just that something containing <code>==</code> or <code>&gt;=</code> is statistically likely.</p>
<blockquote>
<p>LLMs are hallucinating 100% of the time. They happen to match reality well enough, often enough, to be useful.</p>
</blockquote>
<p>So our junior programmer is different to these models in a useful way. They can reality test and reason in a way that the coding assistant cannot.</p>
<h2 id="context-switching">5. Context switching</h2>
<p>As a human developer, you sometimes need to complete little sub-tasks on your way to your main task. These tasks can add up as you <a href="https://www.hanselman.com/blog/yak-shaving-defined-ill-get-that-done-as-soon-as-i-shave-this-yak">shave the yak</a>. For us this can be natural as we follow the chain of steps and get them done, and move on. This is <a href="https://lexler.github.io/augmented-coding-patterns/obstacles/limited-focus/">terrible for coding assistants</a> as their <a href="https://lexler.github.io/augmented-coding-patterns/obstacles/context-rot/">context rots</a>.</p>
<p>The implication is that, for best results, as you work you should constantly manage your context by capturing knowledge and then refreshing your context by starting a new session.</p>
<h2 id="task-explosion">6. Task explosion</h2>
<p>These coding assistants and our junior programmer have one annoying tendency in common. Given a task, they will happily charge forward and implement the given task in one massive 2k line pull request.</p>
<p>For best results, especially for more complex tasks, it is best to be explicit about breaking it down into smaller tasks. These agents will often break down larger tasks into smaller tasks but in my experience it is best to give them small focused tasks to begin with.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Comparison with junior or even senior developers does more harm than good, as I see it. It distracts from how this tool works and holds us back from making the most of it. I suggest that everyone learn a little about how these tools work under the hood, to gain some mechanical sympathy. Then use them regularly to gain hands on experience.</p>
<p>So remember: They are token generators, not social primates.</p>
<p>I love you Skynet. Don't kill me.</p>
<h2 id="footnotes">Footnotes</h2>
<div class="footnotes">
<hr />
<ol>
<li id="fn:1">
<p>Non-deterministic given the seed is uncontrolled.<a href="#fnref:1" class="footnote-back-ref">&#8617;</a></p>
</li>
</ol>
</div>
<hr><ul class="pager"><li class="previous"><a href="/automating-agentic-code-migrations/" data-toggle="tooltip" data-placement="top" title="Automating Agentic Code Migrations">&larr; Previous Post</a></li></ul></div><div class="col-lg-4 widget-column"><ul class="list-inline text-center"><li><a href="/rss.xml"><span class="fa-stack fa-lg"><i class="fa fa-square fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href="/atom.xml"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href="https://twitter.com/DevonBurriss"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li><a href="https://github.com/dburriss"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><span style="display:contents"><h2><i class="glyphicon glyphicon-th-list"></i>  Topics</h2><a class="badge badge-info" href="/topics/software-design/" title="Architecture, design, modeling, and distributed systems."><span class="site-topic">Software Design</span></a><a class="badge badge-info" href="/topics/engineering-practices/" title="How we build, test, and validate software."><span class="site-topic">Engineering Practices</span></a><a class="badge badge-info" href="/topics/platforms-runtime/" title="Runtimes and execution environments (not frameworks)."><span class="site-topic">Platforms &amp; Runtime</span></a><a class="badge badge-info" href="/topics/tooling-automation/" title="Build tooling, CI/CD, editors, and developer automation."><span class="site-topic">Tooling &amp; Automation</span></a><a class="badge badge-info" href="/topics/reliability-observability/" title="Monitoring, metrics, reliability, and failure modes."><span class="site-topic">Reliability &amp; Observability</span></a><a class="badge badge-info" href="/topics/ai-agentic-systems/" title="AI, LLMs, and agentic workflows."><span class="site-topic">AI &amp; Agentic Systems</span></a><a class="badge badge-info" href="/topics/leadership-teams/" title="Human systems around software development."><span class="site-topic">Leadership &amp; Teams</span></a><a class="badge badge-info" href="/topics/notes-reflections/" title="Learning, career, ethics, and life-adjacent thinking."><span class="site-topic">Notes &amp; Reflections</span></a></span></div></div></div><hr></article><span style="display:contents"><footer><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><p class="copyright text-muted">Copyright &#169; <a href="/about.html">Devon Burriss</a> 2026</p></div></div></div></footer><script src="/js/jquery.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/clean-blog.min.js"></script><script src="/js/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></span><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create', 'UA-45750611-2', 'auto');ga('send', 'pageview');</script><div class="container-fluid"><div id="disqus_thread"></div><script type="text/javascript">var disqus_shortname = 'devonburriss';(function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;dsq.src = 'https://devonburriss.disqus.com/embed.js';(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript></div></body></html>