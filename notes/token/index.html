<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="color-scheme" content="dark light"><title>Token</title><meta name="description" content="Mostly explorations in code"><meta name="author" content="Devon Burriss"><meta itemprop="name" content="Token"><meta itemprop="description" content="Mostly explorations in code"><meta itemprop="image" content="https://devonburriss.me/img/explore-590.jpg"><link rel="icon" type="image/png" href="/img/favicon16.png" sizes="16x16"><link rel="icon" type="image/png" href="/img/favicon32.png" sizes="32x32"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@DevonBurriss"><meta name="twitter:title" content="Token"><meta name="twitter:description" content="Mostly explorations in code"><meta name="twitter:creator" content="@DevonBurriss"><meta name="twitter:image" content="https://devonburriss.me/img/explore-590.jpg"><meta property="og:title" content="Token"><meta property="og:type" content="article"><meta property="og:url" content="https://devonburriss.me/notes/token/"><meta property="og:image" content="https://devonburriss.me/img/explore-590.jpg"><meta property="og:description" content="Mostly explorations in code"><meta property="og:site_name" content="Devon Burriss&#39; Blog"><link rel="stylesheet" href="/css/site.css"><link rel="stylesheet" href="/css/highlight/atom-one-dark.css"><script>(function(){try{var t=localStorage.getItem('theme');if(t==='dark'||t==='light'){document.documentElement.dataset.theme=t;}}catch(e){}})();</script><script src="/js/theme.js" defer="defer"></script><script type="module" src="/js/search-ui.js"></script></head><body><header class="site-header"><nav class="site-nav"><a class="site-title nav-badge" href="/">DEVON BURRISS</a><ul class="site-links"><li><a href="/">Home</a></li><li><a href="/topics/">Topics</a></li><li><a href="/notes/">Notes</a></li><li><a href="/recommended-reading.html">Reading</a></li><li><a href="/about/">About</a></li><li><a href="/rss.xml">RSS</a></li></ul><button type="button" class="theme-toggle" id="theme-toggle" aria-label="Toggle light/dark theme">Theme</button></nav></header><main class="site-main"><span style="display:contents"><header class="page-header"><h1>Token</h1><p class="note-meta"><span class="note-status status-draft">draft</span></p></header><div class="topic-pills"><a class="topic-pill" href="/topics/ai-agentic-systems/" title="AI, LLMs, and agentic workflows.">AI &amp; Agentic Systems</a></div><hr></span><article class="prose"><p>Sampling parameters, also known as Inference Parameters, are a collection of input parameters for completions (inference) that can be used to control the output of a <a href="/notes/llm/">LLM</a>.<br />
These parameters affect decoding only and do not change the model’s internal representations or weights.<br />
The sampling parameters operate on the <span class="unresolved-link">Logit</span>s that come out of the <span class="unresolved-link">Neural Network</span>. These parameters give control over the transformation of logits to probability distributions before the <span class="unresolved-link">Sampling</span> into output tokens.</p>
<div class="mermaid">flowchart TB
    A[Input tokens and context] --> B[Neural network forward pass]
    B --> C[Final hidden state]
    C --> D[Linear projection]
    D --> E[Logits per token]

    E --> F[Logit adjustments]

    F --> G[Distribution shaping]
    G --> I[Normalized probability distribution]

    I --> K[Sampling step]
    K --> L[Next token selected]

    subgraph Adjustments
        F1[Logit bias]
        F2[Repetition / frequency penalties]
        F3[Temperature scaling]
    end

    F --> F1
    F --> F2
    F --> F3

    subgraph DistributionShaping[Distribution shaping]
        G1[Softmax]
        G2[Top-k]
        G3[Top-p]
        G4[Typical sampling]
        G5[Renormalization]
    end

    G --> G1
    G --> G2
    G --> G3
    G --> G4
    G --> G5

</div>
<p>Sampling parameters matter because they control the trade-off between determinism, diversity, and failure modes such as repetition or hallucination, without changing the underlying model.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Common default</th>
<th>What change is applied</th>
<th>When to use</th>
<th>Resulting behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td>Temperature</td>
<td>1.0</td>
<td>Divide all logits by T</td>
<td>Control randomness globally</td>
<td>Lower sharpens, higher flattens probability mass</td>
</tr>
<tr>
<td>Top-k</td>
<td>Disabled or 40</td>
<td>Keep k highest logits, mask rest</td>
<td>Cut off long tail</td>
<td>More focus, possible brittleness</td>
</tr>
<tr>
<td>Top-p</td>
<td>1.0 or 0.9</td>
<td>Keep tokens until cumulative probability ≥ p</td>
<td>Adaptive truncation</td>
<td>Stable diversity across contexts</td>
</tr>
<tr>
<td>Min-p</td>
<td>Disabled or 0.05</td>
<td>Drop tokens below fixed probability</td>
<td>Avoid extremely unlikely tokens</td>
<td>Prevents rare noise, risk of collapse</td>
</tr>
<tr>
<td>Typical sampling</td>
<td>Disabled or 0.2</td>
<td>Penalize entropy outliers</td>
<td>Reduce dull or erratic output</td>
<td>More natural phrasing</td>
</tr>
<tr>
<td>Repetition penalty</td>
<td>1.0</td>
<td>Scale down logits of repeated tokens</td>
<td>Prevent loops</td>
<td>Less repetition, weaker emphasis</td>
</tr>
<tr>
<td>Frequency penalty</td>
<td>0.0</td>
<td>Subtract proportional to token count</td>
<td>Reduce word reuse</td>
<td>Increased lexical diversity</td>
</tr>
<tr>
<td>Presence penalty</td>
<td>0.0</td>
<td>Subtract once if token appeared</td>
<td>Encourage topic shift</td>
<td>More exploration</td>
</tr>
<tr>
<td>Logit bias</td>
<td>0</td>
<td>Add fixed per-token offsets</td>
<td>Enforce constraints</td>
<td>Hard steering</td>
</tr>
<tr>
<td>Greedy decoding</td>
<td>Off</td>
<td>Select max logit only</td>
<td>Deterministic tasks</td>
<td>No diversity</td>
</tr>
<tr>
<td>Beam search</td>
<td>Off or 5 beams</td>
<td>Track top sequences</td>
<td>Structured generation</td>
<td>Higher likelihood, dull text</td>
</tr>
</tbody>
</table>
<h2 id="resources">Resources</h2>
<ul>
<li>https://simonwillison.net/2025/May/4/llm-sampling/</li>
<li>https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html</li>
</ul>
</article><hr></main><footer class="site-footer"><p>Copyright &#169; <a href="/about/">Devon Burriss</a> 2026</p></footer><script src="/js/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><span style="display:contents"><script src="/js/vendor/mermaid.min.js" defer="defer"></script><script src="/js/mermaid-init.js" defer="defer"></script></span><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create', 'UA-45750611-2', 'auto');ga('send', 'pageview');</script></body></html>