<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="color-scheme" content="dark light"><title>Sampling Parameters</title><meta name="description" content="Mostly explorations in code"><meta name="author" content="Devon Burriss"><meta itemprop="name" content="Sampling Parameters"><meta itemprop="description" content="Mostly explorations in code"><meta itemprop="image" content="https://devonburriss.me/img/explore-590.jpg"><link rel="icon" type="image/png" href="/img/favicon16.png" sizes="16x16"><link rel="icon" type="image/png" href="/img/favicon32.png" sizes="32x32"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@DevonBurriss"><meta name="twitter:title" content="Sampling Parameters"><meta name="twitter:description" content="Mostly explorations in code"><meta name="twitter:creator" content="@DevonBurriss"><meta name="twitter:image" content="https://devonburriss.me/img/explore-590.jpg"><meta property="og:title" content="Sampling Parameters"><meta property="og:type" content="article"><meta property="og:url" content="https://devonburriss.me/notes/sampling-parameters/"><meta property="og:image" content="https://devonburriss.me/img/explore-590.jpg"><meta property="og:description" content="Mostly explorations in code"><meta property="og:site_name" content="Devon Burriss&#39; Blog"><link rel="stylesheet" href="/css/site.css"><link rel="stylesheet" href="/css/highlight/atom-one-dark.css"><script>(function(){try{var t=localStorage.getItem('theme');if(t==='dark'||t==='light'){document.documentElement.dataset.theme=t;}}catch(e){}})();</script><script src="/js/theme.js" defer="defer"></script><script type="module" src="/js/search-ui.js"></script></head><body><header class="site-header"><nav class="site-nav"><a class="site-title nav-badge" href="/">DEVON BURRISS</a><ul class="site-links"><li><a href="/">Home</a></li><li><a href="/topics/">Topics</a></li><li><a href="/notes/">Notes</a></li><li><a href="/recommended-reading.html">Reading</a></li><li><a href="/about/">About</a></li><li><a href="/rss.xml">RSS</a></li></ul><button type="button" class="theme-toggle" id="theme-toggle" aria-label="Toggle light/dark theme">Theme</button></nav></header><main class="site-main"><span style="display:contents"><header class="page-header"><h1>Sampling Parameters</h1><p class="note-meta"><span class="note-status status-draft">draft</span></p></header><div class="topic-pills"><a class="topic-pill" href="/topics/ai-agentic-systems/" title="AI, LLMs, and agentic workflows.">AI &amp; Agentic Systems</a></div><hr></span><article class="prose"><p>Also known as Inference Parameters.</p>
<p>Sampling parameters are a collection of input parameters for completions (inference) that can be used to control the output of a [[LLM]].</p>
<p>Temperature is the most commonly used parameter to control &quot;creativity&quot;.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Common default</th>
<th>What it does</th>
<th>When to use / trade-offs</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>temperature</strong></td>
<td>0.7</td>
<td>Scales the logits before sampling. Higher = flatter distribution (more randomness). Lower = sharper (more deterministic).</td>
<td>Use low (0–0.3) for factual, repeatable outputs. Use medium (0.5–0.8) for general writing. High (&gt;1.0) increases creativity but raises hallucination risk.</td>
</tr>
<tr>
<td><strong>top_p</strong> (nucleus)</td>
<td>0.9</td>
<td>Samples from the smallest set of tokens whose cumulative probability ≥ <em>p</em>.</td>
<td>Prefer over top_k for adaptive diversity. Lower (0.8–0.9) for control; higher for more variation. Often paired with low temperature.</td>
</tr>
<tr>
<td><strong>top_k</strong></td>
<td>40</td>
<td>Limits sampling to the <em>k</em> most likely tokens.</td>
<td>Useful for hard caps on randomness. Can degrade fluency if too low. Often redundant if using top_p.</td>
</tr>
<tr>
<td><strong>min_p</strong></td>
<td>0.05</td>
<td>Drops tokens whose probability is below a fraction of the max-prob token.</td>
<td>Stabilizes output while allowing diversity. Alternative to top_k/top_p in some stacks.</td>
</tr>
<tr>
<td><strong>presence_penalty</strong></td>
<td>0.0</td>
<td>Penalizes tokens that have appeared anywhere in the output. Encourages topic diversity.</td>
<td>Use for brainstorming or long outputs that tend to loop. Can hurt coherence if too high.</td>
</tr>
<tr>
<td><strong>frequency_penalty</strong></td>
<td>0.0</td>
<td>Penalizes tokens proportional to how often they appear. Reduces repetition.</td>
<td>Use for verbose outputs that repeat phrases. Safer than presence_penalty for prose.</td>
</tr>
<tr>
<td><strong>repetition_penalty</strong></td>
<td>1.0</td>
<td>Multiplies logits of previously generated tokens (&lt;1 penalizes repetition).</td>
<td>Common in open-source models. Set ~1.1–1.2 to reduce loops; too high harms grammar.</td>
</tr>
<tr>
<td><strong>max_tokens</strong></td>
<td>Model-specific</td>
<td>Hard cap on generated tokens.</td>
<td>Always set explicitly in production to control cost and runaway outputs.</td>
</tr>
<tr>
<td><strong>stop_sequences</strong></td>
<td>none</td>
<td>Terminates generation when a token sequence is emitted.</td>
<td>Use to enforce structure (e.g. JSON, sections). Fragile if model paraphrases.</td>
</tr>
<tr>
<td><strong>seed</strong></td>
<td>random</td>
<td>Fixes RNG seed for reproducible sampling.</td>
<td>Use for tests, evals, and diff-based comparisons. Reduces diversity.</td>
</tr>
<tr>
<td><strong>logit_bias</strong></td>
<td>none</td>
<td>Adds or subtracts bias for specific tokens.</td>
<td>Use to ban tokens or strongly steer output. High risk of brittle behavior.</td>
</tr>
<tr>
<td><strong>beam_width / num_beams</strong></td>
<td>1</td>
<td>Searches multiple continuations and picks highest-scoring sequence.</td>
<td>Deterministic, low diversity. Good for short, exact outputs; poor for creative text.</td>
</tr>
<tr>
<td><strong>length_penalty</strong></td>
<td>1.0</td>
<td>Adjusts preference for longer vs shorter beams.</td>
<td>Only relevant with beam search. Tune to avoid overly short answers.</td>
</tr>
</tbody>
</table>
<h2 id="resources">Resources</h2>
<ul>
<li><a href="https://simonwillison.net/2025/May/4/llm-sampling/">https://simonwillison.net/2025/May/4/llm-sampling/</a></li>
<li><a href="https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html">https://docs.vllm.ai/en/v0.6.0/dev/sampling_params.html</a></li>
</ul>
</article><hr><section class="backlinks"><h2>Linked from</h2><ul class="link-list"><li><a href="/notes/large-language-model/">Large-Language Model</a></li></ul></section></main><footer class="site-footer"><p>Copyright &#169; <a href="/about/">Devon Burriss</a> 2026</p></footer><script src="/js/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create', 'UA-45750611-2', 'auto');ga('send', 'pageview');</script></body></html>